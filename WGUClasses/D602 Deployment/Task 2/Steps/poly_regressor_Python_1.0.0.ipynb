{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model to predict airport flight delays</h1><br>\n",
    "<br>\n",
    "Much of this model is taken from the work of Fabien Daniel:<br>\n",
    "https://www.kaggle.com/code/fabiendaniel/predicting-flight-delays-tutorial/notebook.  <br>\n",
    "The difference here is that we are modeling delays for all arrival airports and all airlines given a single departure airport.<br>\n",
    "<br>\n",
    "We also incorporate MLflow tracking using the Python API.  <br>\n",
    "<br>\n",
    "Input parameters for this script include:<br>\n",
    "* num_alpha_increments:  The number of different Ridge regression alpha penalty values to try, spaced by 0.2 apart<br>\n",
    "  <br>\n",
    "Dependencies:<br>\n",
    "* cleaned_data.csv is the input data file, structured appropriately.  The structure of this data file must be:<br>\n",
    "| YEAR | MONTH | DAY | DAY_OF_WEEK | ORG_AIRPORT | DEST_AIRPORT | SCHEDULED_DEPARTURE | DEPARTURE_TIME | DEPARTURE_DELAY | SCHEDULED_ARRIVAL | ARRIVAL_TIME | ARRIVAL_DELAY |<br>\n",
    "|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|<br>\n",
    "| integer | integer | integer | integer | string | string | integer | integer | integer | integer | integer | integer |<br>\n",
    "<br>\n",
    "Outputs:<br>\n",
    "* log file named \"polynomial_regression.txt\" containing information about the model training process<br>\n",
    "* MLFlow experiment named with current date containing model training runs, one for each value of the Ridge regression penalty<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[36]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the packages we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder, OneHotEncoder\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[38]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Checking all versions in YAML file just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Python version: \", python_version())\n",
    "print(\"matplotlib version: \", \"3.7.1\")\n",
    "#Found from terminal\n",
    "print(\"numpy version: \", np.__version__)\n",
    "print(\"searborn version: \", sns.__version__)\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "print(\"mlflow version: \", mlflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the argument parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Parse the parameters for the polynomial regression')\n",
    "parser.add_argument('num_alphas', metavar='N', type=int, help='Number of Lasso penalty increments')\n",
    "order = 1\n",
    "#args = parser.parse_args()\n",
    "#num_alpha_increments = args[0]\n",
    "# Uncomment the two lines above and comment the line below to run this script from the command prompt or as part of an \n",
    "# MLFlow pipeline ## Uncommenting this code does not work. The code does NOT work as instructed. Keeping the base argument.\n",
    "num_alphas = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configure logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = \"polynomial_regression.txt\"\n",
    "logging.basicConfig(filename=logname,\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "logging.info(\"Flight Departure Delays Polynomial Regression Model Log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/cfman/OneDrive/Desktop/WGUClasses/D602 Deployment/Task 2/Data/cleaned_data.csv\")\n",
    "tab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_month_year(df:pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    grab_month_year is a function to extract the month and year of the flights in the departure delay dataset.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        the input data set in Pandas data frame format.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (month,year) of the data set.\n",
    "    Raises\n",
    "    ------\n",
    "    Exception\n",
    "        If more than one month or year are found in the data set.\n",
    "    \"\"\"\n",
    "    months = pd.unique(df['MONTH'])\n",
    "    years = pd.unique(df['YEAR'])\n",
    "    if len(months) >1:\n",
    "        raise Exception(\"Multiple months found in data set, only one acceptable\")\n",
    "    else:\n",
    "        month = int(months[0])\n",
    "    if len(years) > 1:\n",
    "        raise Exception(\"Multiple years found in data set, only one acceptable\")\n",
    "    else:\n",
    "        year = int(years[0])\n",
    "    return (month, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_hour(string: str) -> datetime:\n",
    "    \"\"\"\n",
    "    format_hour is a function to convert an 'HHMM' string input to a time in datetime format.\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : string\n",
    "        An hour and minute in 'HHMM' format.\n",
    "    Returns\n",
    "    -------\n",
    "    datetime\n",
    "        An hour and minute (datetime.time).  Returns nan if input string is null.\n",
    "    \"\"\"    \n",
    "    if pd.isnull(string):\n",
    "        return np.nan\n",
    "    else:\n",
    "        if string == 2400: string = 0\n",
    "        string = \"{0:04d}\".format(int(string))\n",
    "        hour = datetime.time(int(string[0:2]), int(string[2:4]))\n",
    "        return hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_hour(x: list) -> datetime:\n",
    "    \"\"\"\n",
    "    combine_date_hour is a function that combines a date and time to produce a datetime.datetime\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list\n",
    "        A list containing a date and a time in datetime format.\n",
    "    Returns\n",
    "    -------\n",
    "    datetime\n",
    "        A combined date and time in datetime format. Returns nan if time is null.\n",
    "    \"\"\"\n",
    "    if pd.isnull(x.iloc[0]) or pd.isnull(x.iloc[1]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return datetime.datetime.combine(x.iloc[0],x.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flight_time(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    create_flight_time is a function that combines two columns of a data frame to produce a datetime.datetime series.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        A data frame containing flight departure delay data\n",
    "    col: string\n",
    "        The name of one of the columns in the data frame containing flight departure delay data\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        A Pandas series of datetimes with combined date and time\n",
    "    \"\"\"\n",
    "    list = []\n",
    "    for index, cols in df[['DATE', col]].iterrows():\n",
    "        if pd.isnull(cols.iloc[1]):\n",
    "            list.append(np.nan)\n",
    "        elif float(cols.iloc[1]) == 2400:\n",
    "            cols.iloc[0] += datetime.timedelta(days=1)\n",
    "            cols.iloc[1] = datetime.time(0,0)\n",
    "            list.append(combine_date_hour(cols))\n",
    "        else:\n",
    "            cols.iloc[1] = format_hour(cols.iloc[1])\n",
    "            list.append(combine_date_hour(cols))\n",
    "    return pd.Series(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[7]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    create_df is a function that wrangles data within a flight departure delay data frame into the format needed for ML training.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        A data frame containing flight departure delay data\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A Pandas data frame with modified columns and data formats suitable for regression model training\n",
    "    \"\"\"\n",
    "    df2 = df[['SCHEDULED_DEPARTURE','SCHEDULED_ARRIVAL',\n",
    "                                    'DEST_AIRPORT','DEPARTURE_DELAY']]\n",
    "    df2 = df2.dropna(how = 'any')\n",
    "    df2.loc[:,'weekday'] = df2['SCHEDULED_DEPARTURE'].apply(lambda x:x.weekday())\n",
    "    #____________________\n",
    "    # delete delays > 1h\n",
    "    df2.loc[:,'DEPARTURE_DELAY'] = df2['DEPARTURE_DELAY'].apply(lambda x:x if x < 60 else np.nan)\n",
    "    df2 = df2.dropna(how = 'any')\n",
    "    #_________________\n",
    "    # formating times\n",
    "    fct = lambda x:x.hour*3600+x.minute*60+x.second\n",
    "    df2.loc[:,'hour_depart'] = df2['SCHEDULED_DEPARTURE'].apply(lambda x:x.time())\n",
    "    df2.loc[:,'hour_depart'] = df2['hour_depart'].apply(fct)\n",
    "    df2.loc[:,'hour_arrive'] = df2['SCHEDULED_ARRIVAL'].apply(fct)\n",
    "    df2 = df2[['hour_depart','hour_arrive',\n",
    "            'DEST_AIRPORT','DEPARTURE_DELAY','weekday']]\n",
    "    df3 = df2.groupby(['hour_depart', 'hour_arrive', 'DEST_AIRPORT'],\n",
    "                      as_index = False).mean()\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nowdate = datetime.date.today()\n",
    "# creates an experiment name that changes every day\n",
    "experiment_name = \"Airport Departure Delays, experiment run on \" + str(nowdate)\n",
    "# creates new experiment if there is not one yet today, otherwise sets the experiment to the existing one for today\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "run_name = \"Run started at \" + datetime.datetime.now().strftime(\"%H:%M\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df[['YEAR','MONTH', 'DAY']])\n",
    "(month,year) = grab_month_year(df)\n",
    "logging.info(\"Month and year of data: %s %s\", month, year)\n",
    "df['SCHEDULED_DEPARTURE'] = create_flight_time(df, 'SCHEDULED_DEPARTURE')\n",
    "df['DEPARTURE_TIME'] = df['DEPARTURE_TIME'].apply(format_hour)\n",
    "df['SCHEDULED_ARRIVAL'] = df['SCHEDULED_ARRIVAL'].apply(format_hour)\n",
    "df['ARRIVAL_TIME'] = df['ARRIVAL_TIME'].apply(format_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define training data as the first 3 weeks of the month, and test data as that from the fourth week of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['SCHEDULED_DEPARTURE'].apply(lambda x:x.date()) < datetime.date(year, month, 23)]\n",
    "df_test  = df[df['SCHEDULED_DEPARTURE'].apply(lambda x:x.date()) > datetime.date(year, month, 23)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = create_df(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[12]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform one-hot encoding of all destination airports in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df3['DEST_AIRPORT'])\n",
    "#_________________________________________________________\n",
    "zipped = zip(integer_encoded, df3['DEST_AIRPORT'])\n",
    "label_airports = list(set(list(zipped)))\n",
    "label_airports.sort(key = lambda x:x[0])\n",
    "#_________________________________________________\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "#_________________________________________________\n",
    "b = np.array(df3[['hour_depart', 'hour_arrive']])\n",
    "X = np.hstack((onehot_encoded, b))\n",
    "Y = np.array(df3['DEPARTURE_DELAY'])\n",
    "Y = Y.reshape(len(Y), 1)\n",
    "logging.info(\"Airport one-hot encoding successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[13]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/validation split at 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[14]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id = experiment.experiment_id, run_name=run_name):\n",
    "    score_min = 10000\n",
    "    alpha_max = num_alphas * 2\n",
    "    count = 1\n",
    "    # loop through all alpha values\n",
    "    for alpha in range(0, alpha_max, 2):\n",
    "        run_num = \"Training Run Number \" + str(count)\n",
    "        # create a Ridge regressor with the stated alpha\n",
    "        ridgereg = Ridge(alpha = alpha/10)\n",
    "        # create polynomial features based on the polyniomial order\n",
    "        poly = PolynomialFeatures(degree = order)\n",
    "        # fit the model using the training data\n",
    "        X_ = poly.fit_transform(X_train)\n",
    "        ridgereg.fit(X_, Y_train)\n",
    "        X_ = poly.fit_transform(X_validate)\n",
    "        # predict against the validation data\n",
    "        result = ridgereg.predict(X_)\n",
    "        # how well did the model do when compared to the validation actuals?\n",
    "        score = metrics.mean_squared_error(result, Y_validate)\n",
    "        with mlflow.start_run(run_name = run_num,nested=True):\n",
    "            mlflow.log_param(\"alpha\",alpha/10)\n",
    "            mlflow.log_metric(\"Training Data Mean Squared Error\",score)\n",
    "            mlflow.log_metric(\"Training Data Average Delay\",np.sqrt(score))\n",
    "        if score < score_min:\n",
    "            score_min = score\n",
    "            parameters = [alpha, order]\n",
    "        logging.info(\"n={} alpha={} , MSE = {:<0.5}\".format(order, alpha/10, score))\n",
    "        count +=1\n",
    "    # train and predict on validation data with optimal alpha found\n",
    "    X_ = poly.fit_transform(X_validate)\n",
    "    tresult = ridgereg.predict(X_)\n",
    "    tscore = metrics.mean_squared_error(tresult, Y_validate)\n",
    "    logging.info('Training Data Final MSE = {}'.format(round(tscore, 2)))\n",
    "    mlflow.log_metric(\"Training Data Mean Squared Error\",tscore)\n",
    "    mlflow.log_metric(\"Training Data Average Delay\",np.sqrt(tscore))\n",
    "mlflow.end_run()\n",
    "logging.info(\"Model training loop completed with %s iterations\", count-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[15]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a data frame of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = create_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_conversion = dict()\n",
    "for s in label_airports:\n",
    "    label_conversion[s[1]] = int(s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export airport label conversion for test data to json file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonout = json.dumps(label_conversion)\n",
    "f = open(\"airport_encodings.json\",\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write json object to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.write(jsonout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()\n",
    "logging.info(\"Export of airport one-hot encoding successful\")\n",
    "df3.loc[:,'DEST_AIRPORT'] = df3.loc[:,'DEST_AIRPORT'].map(pd.Series(label_conversion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually one-hot encode destination airports for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, label in label_airports:\n",
    "    temp = df3['DEST_AIRPORT'] == index\n",
    "    temp = temp.apply(lambda x:1.0 if x else 0.0)\n",
    "    if index == 0:\n",
    "        matrix = np.array(temp)\n",
    "    else:\n",
    "        matrix = np.vstack((matrix, temp))\n",
    "matrix = matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(df3[['hour_depart', 'hour_arrive']])\n",
    "X_test = np.hstack((matrix, b))\n",
    "Y_test = np.array(df3['DEPARTURE_DELAY'])\n",
    "Y_test = Y_test.reshape(len(Y_test), 1)\n",
    "logging.info(\"Wrangling of test data successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[16]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create polynomial features based on order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = poly.fit_transform(X_test)\n",
    "# predict on last week of month data\n",
    "result = ridgereg.predict(X_)\n",
    "score = metrics.mean_squared_error(result, Y_test)\n",
    "logging.info('Test Data MSE = {}'.format(round(score, 2)))\n",
    "logging.info(\"Predictions using test data successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[17]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Test Data average delay = {:.2f} min'.format(np.sqrt(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[18]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(ridgereg, open(filename, 'wb'))\n",
    "logging.info(\"Final model export successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[19]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create and export model performance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.DataFrame()\n",
    "tips[\"prediction\"] = pd.Series([float(s) for s in result[:,0]]) \n",
    "tips[\"original_data\"] = pd.Series([float(s) for s in Y[:,0]]) \n",
    "sns.jointplot(x=\"original_data\", y=\"prediction\", data=tips, height = 6, ratio = 7,\n",
    "              joint_kws={'line_kws':{'color':'limegreen'}}, kind='reg')\n",
    "plt.xlabel('Mean delays (min)', fontsize = 15)\n",
    "plt.ylabel('Predictions (min)', fontsize = 15)\n",
    "plt.plot(list(range(-10,25)), list(range(-10,25)), linestyle = ':', color = 'r')\n",
    "plt.savefig(\"model_performance_test.jpg\",dpi=300)\n",
    "logging.info(\"Model performance plot export successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[20]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[23]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: create an MLFlow run within the current experiment that logs the following as artifacts, parameters, <br>\n",
    "or metrics, as appropriate, within the experiment: <br>\n",
    "1.  The informational log files generated from the import_data and clean_data scripts<br>\n",
    "2.  the input parameters (alpha and order) to the final regression against the test data<br>\n",
    "3.  the performance plot<br>\n",
    "4.  the model performance metrics (mean squared error and the average delay in minutes)<br>\n",
    "https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=6025520f-a6cc-4fcd-9234-b25300068d11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id = experiment.experiment_id, run_name=run_name):\n",
    "    score_min = 10000\n",
    "    alpha_max = num_alphas * 2\n",
    "    count = 1\n",
    "    # loop through all alpha values\n",
    "    for alpha in range(0, alpha_max, 2):\n",
    "        run_num = \"Testing Run Number \" + str(count)\n",
    "        # create a Ridge regressor with the stated alpha\n",
    "        ridgereg = Ridge(alpha = alpha/10)\n",
    "        # create polynomial features based on the polyniomial order\n",
    "        poly = PolynomialFeatures(degree = order)\n",
    "        # fit the model using the training data\n",
    "        X_ = poly.fit_transform(X_train)\n",
    "        ridgereg.fit(X_, Y_train)\n",
    "        X_ = poly.fit_transform(X_test)\n",
    "        # predict against the validation data\n",
    "        result = ridgereg.predict(X_)\n",
    "        # how well did the model do when compared to the validation actuals?\n",
    "        score = metrics.mean_squared_error(result, Y_test)\n",
    "        with mlflow.start_run(run_name = run_num,nested=True):\n",
    "            mlflow.log_param(\"alpha\",alpha/10)\n",
    "            mlflow.log_metric(\"Testing Data Mean Squared Error\",score)\n",
    "            mlflow.log_metric(\"Testing Data Average Delay\",np.sqrt(score))\n",
    "        if score < score_min:\n",
    "            score_min = score\n",
    "            parameters = [alpha, order]\n",
    "        logging.info(\"n={} alpha={} , MSE = {:<0.5}\".format(order, alpha/10, score))\n",
    "        count +=1\n",
    "    # train and predict on validation data with optimal alpha found\n",
    "    X_ = poly.fit_transform(X_test)\n",
    "    tresult = ridgereg.predict(X_)\n",
    "    tscore = metrics.mean_squared_error(tresult, Y_test)\n",
    "    logging.info('Training Data Final MSE = {}'.format(round(tscore, 2)))\n",
    "    mlflow.log_metric(\"Testing Data Mean Squared Error\",tscore)\n",
    "    print(\"Testing Data Mean Squared Error\",tscore)\n",
    "    mlflow.log_metric(\"Testing Data Average Delay\",np.sqrt(tscore))\n",
    "    print(\"Testing Data Average Delay\",np.sqrt(tscore))\n",
    "    mlflow.log_metric(\"Alpha level \", alpha)\n",
    "    mlflow.log_metric(\"Order \", order)\n",
    "    mlflow.log_artifact(\"exported_data.txt\", \"imported_data.txt\")\n",
    "    \n",
    "        # create and export model performance plot\n",
    "    tips = pd.DataFrame()\n",
    "    tips[\"prediction\"] = pd.Series([float(s) for s in result[:,0]]) \n",
    "    tips[\"original_data\"] = pd.Series([float(s) for s in Y_test[:,0]]) \n",
    "    sns.jointplot(x=\"original_data\", y=\"prediction\", data=tips, height = 6, ratio = 7,\n",
    "                  joint_kws={'line_kws':{'color':'limegreen'}}, kind='reg')\n",
    "    plt.xlabel('Mean delays (min)', fontsize = 15)\n",
    "    plt.ylabel('Predictions (min)', fontsize = 15)\n",
    "    plt.plot(list(range(-10,25)), list(range(-10,25)), linestyle = ':', color = 'r')\n",
    "    plt.savefig(\"model_performance_test.jpg\",dpi=300)\n",
    "    logging.info(\"Model performance plot export successful\")\n",
    "mlflow.end_run()\n",
    "logging.info(\"Model Testing loop completed with %s iterations\", count-1)\n",
    "print(\"MLflow run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[22]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
